# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'EasyLabelingSimple.ui'
#
# Created by: PyQt5 UI code generator 5.15.6
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

#for central functions
from tqdm import tqdm
import cv2
import tensorflow as tf
from PIL import Image
import numpy as np
import os
from os import listdir
from xml.etree.ElementTree import Element, SubElement, ElementTree
assert tf.__version__.startswith('2')

tf.get_logger().setLevel('ERROR')
from absl import logging
logging.set_verbosity(logging.ERROR)


#for GUI codes
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QFileDialog
from PyQt5.QtGui import QIcon

#Global Variables
DETECTION_THRESHOLD = 0.4

#인풋 모델
model_path = '/Users/ijiwon/Desktop/effi_1_conv_model.tflite'

#인풋 사진
INPUT_IMAGE_URL = '/Users/ijiwon/Desktop/3/'


class Ui_MainWindow(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(640, 480)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.gridLayout_2 = QtWidgets.QGridLayout(self.centralwidget)
        self.gridLayout_2.setObjectName("gridLayout_2")
        self.gridLayout = QtWidgets.QGridLayout()
        self.gridLayout.setObjectName("gridLayout")

        self.pushButton = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton.setObjectName("pushButton")
        self.pushButton.clicked.connect(self.clickAugmentations)

        self.gridLayout.addWidget(self.pushButton, 0, 0, 1, 1)

        self.pushButton_3 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_3.setObjectName("pushButton_3")
        self.pushButton_3.clicked.connect(self.clickImageFolder)

        self.gridLayout.addWidget(self.pushButton_3, 0, 1, 1, 1)

        self.pushButton_2 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_2.setObjectName("pushButton_2")
        self.pushButton_2.clicked.connect(self.clickAugmentations)

        self.gridLayout.addWidget(self.pushButton_2, 1, 0, 1, 1)

        self.pushButton_4 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_4.setObjectName("pushButton_4")
        self.pushButton_4.clicked.connect(self.clickTFliteModel)

        self.gridLayout.addWidget(self.pushButton_4, 1, 1, 1, 1)

        self.pushButton_5 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_5.setObjectName("pushButton_5")
        self.pushButton_5.clicked.connect(self.clickStartEasyLabeling)

        self.gridLayout.addWidget(self.pushButton_5, 2, 0, 1, 2)
        self.gridLayout_2.addLayout(self.gridLayout, 0, 0, 1, 1)
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 640, 24))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def clickAugmentations(self):
        print("Augmentations")

        #TODO
        # use imgaug library
        # if someone doesn't have enough
        # images, use this function.
        # you can choose 4 kinds of options
        # that is snowy, foggy, rainy, darker
    

    def clickImageFolder(self):
        print("ImageFolder")
        imageFolder = str(QFileDialog.getExistingDirectory(None, "Select Image Directory"))
        INPUT_IMAGE_URL=imageFolder
        print("selected folder's directory is "+imageFolder)
        #TODO
        # open directory folder of image files
        # if someone select video file,
        # by using ffmpeg, make that video file
        # a lot of frames of photos
        # and then, show him/her numbers of images
        # that he/she chose
        # check that images is good for using this library.
        # if not, t

    def clickTFliteModel(self):
        print("TFliteModel")
        modelFile=str(QFileDialog.getOpenFileName(None, 'Hey! Select a TFlite Model', "" , filter='*.tflite'))
        model_path=modelFile
        print("selected TFlite model's directroy is "+modelFile)
        #TODO
        # open directory folder
        # to select tflite model
        # if you don't have tflite model
        # link which is colab computer or
        # select the trained model 

    def clickStartEasyLabeling(self):
        print("EasyLabeling")      
        easyLabeling()
        #TODO
        # 클릭하면 great_scale.py에
        # 작성된 코드 작동시키기


    def clickAboutcarVon(self):
        print("carVon is a good company")
        #TODO
        # 클릭하면 깃허브 링크로 연결되도록 하기  

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.setWindowIcon(QIcon('/Users/ijiwon/workspace/python_code/Easy-Labeling/pngegg.png'))
        self.pushButton.setText(_translate("MainWindow", "Augmentations"))
        self.pushButton_3.setText(_translate("MainWindow", "Image Folder"))
        self.pushButton_2.setText(_translate("MainWindow", "About carVon"))
        self.pushButton_4.setText(_translate("MainWindow", "TFlite Model"))
        self.pushButton_5.setText(_translate("MainWindow", "Start Easy-Labeling"))


def read_train_dataset(dir):
    images = []

    for file in listdir(dir):
        if 'jpg' in file.lower() or 'png' in file.lower():
            images.append(cv2.imread(dir + file, 1))

    images = np.array(images)

    return images

def preprocess_image(image_path, input_size):
  """Preprocess the input image to feed to the TFLite model"""
  img = tf.io.read_file(image_path)
  img = tf.io.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.uint8)
  original_image = img
  resized_img = tf.image.resize(img, input_size)
  resized_img = resized_img[tf.newaxis, :]
  return resized_img, original_image


def set_input_tensor(interpreter, image):
  """Set the input tensor."""
  tensor_index = interpreter.get_input_details()[0]['index']
  input_tensor = interpreter.tensor(tensor_index)()[0]
  input_tensor[:, :] = image


def get_output_tensor(interpreter, index):
  """Retur the output tensor at the given index."""
  output_details = interpreter.get_output_details()[index]
  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))
  return tensor


def detect_objects(interpreter, image, threshold):
  """Returns a list of detection results, each a dictionary of object info."""
  # Feed the input image to the model
  set_input_tensor(interpreter, image)
  interpreter.invoke()

  # Get all outputs from the model
  #300 ssd model
  #boxes = get_output_tensor(interpreter, 0)
  #classes = get_output_tensor(interpreter, 1)
  #scores = get_output_tensor(interpreter, 2)
  #count = int(get_output_tensor(interpreter, 3))

  #efficient model
  boxes = get_output_tensor(interpreter, 1)
  classes = get_output_tensor(interpreter, 3)
  scores = get_output_tensor(interpreter, 0)
  count = int(get_output_tensor(interpreter, 2))

  
  #print(boxes)
  #print(scores)
  #print(count)
  #count=len(count)

  results = []
  for i in range(count):
    if scores[i] >= threshold:
      result = {
        'bounding_box': boxes[i],
        'class_id': classes[i],
        'score': scores[i]
      }
      results.append(result)
  return results


def run_odt_and_draw_results(image_path, imageName, interpreter, threshold):
  """Run object detection on the input image and draw the detection results"""
  # Load the input shape required by the model
  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']

  # Load the input image and preprocess it
  preprocessed_image, original_image = preprocess_image(
      image_path, 
      (input_height, input_width)
    )

  # Run object detection on the input image
  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)

  # Plot the detection results on the input image
  original_image_np = original_image.numpy().astype(np.uint8)

  makeAnnotation(imageName, results, original_image_np)
    
  #print("success")


def makeAnnotation(imageName, results, original_image_np ):
    filename = imageName #이름을 넣어주자
    width = original_image_np.shape[1]
    height = original_image_np.shape[0]
 
    root = Element('annotation')
    SubElement(root, 'folder').text = 'ijiwon'
    SubElement(root, 'filename').text = filename + '.jpg'  #jpg로 할 지 다른 것으로 할지는 나중에 인풋으로 넣어보자
    SubElement(root, 'path').text = './object_detection/images' +  filename + '.jpg' #jpg로 할 지 다른 것으로 할지는 나중에 인풋으로 넣어보자
    source = SubElement(root, 'source')
    SubElement(source, 'database').text = 'Unknown'
 
    size = SubElement(root, 'size')
    SubElement(size, 'width').text = str(width)
    SubElement(size, 'height').text = str(height)
    SubElement(size, 'depth').text = '3'
 
    SubElement(root, 'segmented').text = '0'
    
    ###################나중에 위치 옮기자
    classes=['child_sign','person','car_rear','bicycle','kickboard','motorcycle','30','40','50','60','70']
    
    #편의점 용 classes
    #classes=['beer_berni', 'beer_blanc', 'beer_bud', 'beer_cass_fresh', 'beer_cloud_original', 'beer_filgood_7', 'beer_filgood_original', 'beer_filite_original', 'beer_heineken', 'beer_terra', 'beer_tsingtao', 'can_2per', 'can_chilsung', 'can_coca_zero', 'can_demi_apple', 'can_demi_lemon', 'can_fanta_orange', 'can_gatorade', 'can_mac_col', 'can_milkis', 'can_mountdew', 'can_pearjuice', 'can_pocari', 'can_powerade', 'can_sprite', 'can_toreta', 'juice_capri-sun_orange', 'milk_banana', 'milk_banana_lite', 'milk_chocochoco', 'milk_coffeecoffee', 'milk_deliciousmilk_300', 'soju_drop_fresh', 'soju_drop_jamong', 'soju_drop_original', 'soju_goodday_blueberry', 'soju_jinro', 'soju_likefirst', 'soju_likefirst_soft', 'soju_maehwa', 'viyott_chococrispy', 'viyott_cookiecream', 'viyott_crunch']
    
    for obj in results:
        # Convert the object bounding box from relative coordinates to absolute 
        # coordinates based on the original image resolution
        ymin, xmin, ymax, xmax = obj['bounding_box']
        xmin = int(xmin * original_image_np.shape[1])
        xmax = int(xmax * original_image_np.shape[1])
        ymin = int(ymin * original_image_np.shape[0])
        ymax = int(ymax * original_image_np.shape[0])
        # Find the class index of the current object
        class_id = classes[int(obj['class_id'])]

        obj = SubElement(root, 'object')
        SubElement(obj, 'name').text = class_id
        SubElement(obj, 'pose').text = 'Unspecified'
        SubElement(obj, 'truncated').text = '0'
        SubElement(obj, 'difficult').text = '0'
        bbox = SubElement(obj, 'bndbox')
        SubElement(bbox, 'xmin').text = str(xmin)
        SubElement(bbox, 'ymin').text = str(ymin)
        SubElement(bbox, 'xmax').text = str(xmax)
        SubElement(bbox, 'ymax').text = str(ymax)
    
    fileName=imageName.rsplit('.')[0]
    tree = ElementTree(root)
    tree.write('/Users/ijiwon/Desktop/3/'+fileName+'.xml')

def easyLabeling():
    # Load the TFLite model
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()

    imagesTo=[]

    for file in listdir(INPUT_IMAGE_URL):
        imagesTo.append(file)

    imagesTo.sort()

    pbar=tqdm(total=len(imagesTo))
    i=0

    for file in imagesTo:
        pbar.update(i)
        i+=1
        detection_result_image = run_odt_and_draw_results(
                INPUT_IMAGE_URL+file, 
                file,
                interpreter, 
                threshold=DETECTION_THRESHOLD
            )
    pbar.close()

if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
